+++
title = "Multimodal public speaking performance assessment"
date = 2015-11-01
authors = ["T. WÃ¶rtwein", "L.-P. Morency", "M. Chollet", "R. Stiefelhagen", "B. Schauerte", "S. Scherer"]
publication_types = ["1"]
abstract = "The ability to speak proficiently in public is essential for many professions and in everyday life. Public speaking skills are difficult to master and require extensive training. Recent developments in technology enable new approaches for public speaking training that allow users to practice in engaging and interactive environments. Here, we focus on the automatic assessment of nonverbal behavior and multimodal modeling of public speaking behavior. We automatically identify audiovisual nonverbal behaviors that are correlated to expert judges' opinions of key performance aspects. These automatic assessments enable a virtual audience to provide feedback that is essential for training during a public speaking performance. We utilize multimodal ensemble tree learners to automatically approximate expert judges' evaluations to provide post-hoc performance assessments to the speakers. Our automatic performance evaluation is highly correlated with the experts' opinions with r = 0.745 for the overall performance assessments. We compare multimodal approaches with single modalities and find that the multimodal ensembles consistently outperform single modalities."
selected = false
publication = "*Proceedings of the 2015 ACM International Conference on Multimodal Interaction, ICMI 2015*"
tags = ["Cicero", "Multimodal Behavior Understanding", "Machine Learning",  "Social Skills Training"]
doi = "10.1145/2818346.2820762"
projects=["Cicero"]
+++
